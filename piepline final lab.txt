import pysparkfrom pyspark
import SparkContext,SparkConf from pyspark.sql.types import 
from pyspark.sql import SQLContext
from pyspark.sql.functions import col 
from pyspark.sql import HiveContext 
import datetime


sqlContext = SQLContext (sc) 

sqlContext = HiveContext (sc)

df_retail_sales = hive_context.table("retail_project.retail_sales")

df_retail_stores = hive_context.table("retail_project.retail_stores")

df_retail_features = hive_context.table("retail_project.retail_features")

sqlContext.registerDataFrameAsTable(df_retail_sales, "spark_tab_retail_sales")

sqlContext.registerDataFrameAsTable(df_retail_stores, "spark_tab_retail_stores")

sqlContext.registerDataFrameAsTable(df_retail_features, "spark_tab_retail_features")


query_01 = open("/root/etl_retail/query_files/query_01.txt")

query01 = query_01.read()

df_q1 = sqlContext.sql(query_01)

sqlContext.registerDataFrameAsTable(df_q1, "temp_tab01")

df_q1.show()


query_02 = open("/root/final_lab/query_files/query_02.txt")

query02 = query_02.read()

df_q2 = sqlContext.sql(query02)

sqlContext.registerDataFrameAsTable(df_q2, "temp_tab02")

df_q2.show()


query_03 = open("/root/etl_retail/query_files/query_02.txt")

query03 = query_03.read()

df_q3 = sqlContext.sql(query03)

sqlContext.registerDataFrameAsTable(df_q3, "temp_tab03")

df_q3.show()

hive_context.sql("DROP TABLE IF EXISTS retail_project.htab01")

hive_context.sql("create table retail_project.htab01 as select * from temp_tab01");

hive_context.sql("DROP TABLE IF EXISTS retail_project.htab02")

hive_context.sql("create table retail_project.htab02 as select * from temp_tab02");

hive_context.sql("DROP TABLE IF EXISTS retail_project.htab03")

hive_context.sql("create table retail_project.htab01 as select * from temp_tab03");

quit()

hive

use retail_project

select * from htab01;